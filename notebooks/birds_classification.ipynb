{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jfSC0OyF11Zo"
      },
      "outputs": [],
      "source": [
        "# Classic data science libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "# Torch libaries \n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models.resnet import ResNet18_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrKTEW1UHH50",
        "outputId": "c0ab00b9-a791-4bbf-e47a-61255b6fac21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
        "print('Device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oVTxCHPQ1KE3"
      },
      "outputs": [],
      "source": [
        "# set random seed\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eZNFqiXfsu1A"
      },
      "outputs": [],
      "source": [
        "# Define Birds dataset class\n",
        "class BirdsDataset(Dataset):\n",
        "    def __init__(self, path, transform=None):\n",
        "        # Check if we have the dataset\n",
        "        if 'birds' not in os.listdir('./'):\n",
        "            print('Dataset is not exist. You must download it.')\n",
        "        else:\n",
        "            self.data = ImageFolder(root=path, transform=transform)\n",
        "            self.classes = self.data.classes\n",
        "            self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.data[index]\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def download():\n",
        "        if 'birds' not in os.listdir('./'):\n",
        "            files.upload()\n",
        "            os.system('mkdir ~/.kaggle')\n",
        "            os.system('cp kaggle.json ~/.kaggle/')\n",
        "            os.system('chmod 600 ~/.kaggle/kaggle.json')\n",
        "            os.system('kaggle datasets download -d gpiosenka/100-bird-species')\n",
        "            os.system('unzip 100-bird-species.zip -d birds')\n",
        "            if 'birds' not in os.listdir('./'):\n",
        "                print('The dataset has been downloaded.')\n",
        "            else:\n",
        "                print('There was an error during the download process.')\n",
        "        else:\n",
        "            print('The dataset already exists.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyirTMcouRxj",
        "outputId": "976f01e0-e3c6-43bd-921a-2c59307f52c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dataset already exists.\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "BirdsDataset.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Mj2cE5BA7sL0"
      },
      "outputs": [],
      "source": [
        "# Set configurations\n",
        "class CONFIG:\n",
        "    # Paths\n",
        "    ROOT_PATH   = Path('./birds')\n",
        "    TRAIN_DIR   = ROOT_PATH.joinpath('train')\n",
        "    VALID_DIR   = ROOT_PATH.joinpath('valid')\n",
        "    TEST_DIR    = ROOT_PATH.joinpath('test')\n",
        "    # Constants of datasets\n",
        "    TARGET_SIZE = (224, 224)\n",
        "    CHANNELS    = 3\n",
        "    INPUT_SHAPE = (CHANNELS, *TARGET_SIZE)\n",
        "    NUM_CLASSES = 500\n",
        "    # Constants of training\n",
        "    BATCH_SIZE  = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7j3kZ7eXAikX"
      },
      "outputs": [],
      "source": [
        "# Define the data transformations\n",
        "\n",
        "# for train/valid\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((CONFIG.TARGET_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# for test\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((CONFIG.TARGET_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the data and apply transformations\n",
        "TRAINSET = BirdsDataset(CONFIG.TRAIN_DIR, transform=train_transform)\n",
        "VALIDSET = BirdsDataset(CONFIG.VALID_DIR, transform=train_transform)\n",
        "TESTSET = BirdsDataset(CONFIG.TEST_DIR, transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2EuEGM3qF5G"
      },
      "outputs": [],
      "source": [
        "# Show exmples of transformations\n",
        "print('Original image')\n",
        "img = TESTSET[4][0]\n",
        "plt.imshow(img.permute(1,2,0))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print('After some transformations')\n",
        "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 7))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(train_transform(transforms.ToPILImage()(img)).permute(1, 2, 0))\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzHf-0prb0f-"
      },
      "outputs": [],
      "source": [
        "# Plot some examples\n",
        "random_index = np.random.randint(0, len(TESTSET), 21)\n",
        "fig, axes = plt.subplots(nrows=3, ncols=7,figsize=(18, 7))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(TESTSET[random_index[i]][0].permute(1, 2, 0))\n",
        "    ax.set_title(TESTSET.classes[TESTSET[random_index[i]][1]], fontsize='small')\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuPeNaeUFVLQ"
      },
      "outputs": [],
      "source": [
        "# Set dataloaders\n",
        "train_dataloader = DataLoader(TRAINSET, batch_size=CONFIG.BATCH_SIZE, shuffle=True)\n",
        "valid_dataloader = DataLoader(VALIDSET, batch_size=CONFIG.BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(TESTSET, batch_size=CONFIG.BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2xGkok86IYh"
      },
      "outputs": [],
      "source": [
        "# Download and load the pre-trained ResNet-18 model\n",
        "model = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "# add our costum output layer\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, CONFIG.NUM_CLASSES)\n",
        "# show model architecture\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBYznZaet31b"
      },
      "outputs": [],
      "source": [
        "# Count the number of parameters in the model\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"The model has {num_params:,} parameters.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfBQUD6gYA6r"
      },
      "outputs": [],
      "source": [
        "# test the Network \n",
        "data = torch.randn(1, *CONFIG.INPUT_SHAPE)\n",
        "model(data).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwDP6QWcYfoL"
      },
      "outputs": [],
      "source": [
        "# set loss_fct and optimizer \n",
        "loss_fct = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EwpsWZfZaO3"
      },
      "outputs": [],
      "source": [
        "# move model to gpu/cpu\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):\n",
        "    model.train()  # Set the model to training mode\n",
        "    train_correct = 0.0\n",
        "    train_loss = 0.0\n",
        "    total = 0.0\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        images, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images.to(device))\n",
        "        loss = loss_fct(outputs.to(device), labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        total += labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_correct += (predicted == labels.to(device)).sum().item()\n",
        "        accuracy = train_correct * 100 / total\n",
        "        if i % 30 == 29:\n",
        "            print('[Epoch %d, Batch %d] Train Loss: %.3f, Train Accuracy: %.2f%%' % (epoch + 1, i + 1, train_loss / 30, accuracy))\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            total = 0\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    valid_loss = 0.0\n",
        "    valid_correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(valid_dataloader):\n",
        "            images, labels = data\n",
        "            outputs = model(images.to(device))\n",
        "            loss = loss_fct(outputs.to(device), labels.to(device))\n",
        "            valid_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            valid_correct += (predicted == labels.to(device)).sum().item()\n",
        "        accuracy = 100 * valid_correct / total\n",
        "        print('[Epoch %d] Valid Loss: %.3f, Valid Accuracy: %.2f%%' % (epoch + 1, valid_loss / len(valid_dataloader), accuracy))\n",
        "        torch.save(model, f'./model_epoch{epoch+1}.pth')\n",
        "\n",
        "print('Finished training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuyYJgAZV2Vq"
      },
      "outputs": [],
      "source": [
        "# Load the saved model\n",
        "model = torch.load('./model_epoch4.pth')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sskl_xWUVk00"
      },
      "outputs": [],
      "source": [
        "# Validation loop \n",
        "model.eval()  # Set the model to evaluation mode\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_dataloader):\n",
        "        images, labels = data\n",
        "        outputs = model(images.to(device))\n",
        "        loss = loss_fct(outputs.to(device), labels.to(device))\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        test_correct += (predicted == labels.to(device)).sum().item()\n",
        "    accuracy = 100 * test_correct / total\n",
        "print('Test Loss: %.3f, Test Accuracy: %.2f%%' % (test_loss / len(valid_dataloader), accuracy))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
